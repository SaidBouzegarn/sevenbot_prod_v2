{
  "OPENAI_MODELS": [
    "gpt-3.5-turbo",
    "gpt-3.5-turbo-16k",
    "gpt-4o",
    "gpt-4",
    "gpt-4o-mini",
    "gpt-4-32k",
    "gpt-4-turbo-preview",
    "gpt-4-1106-preview",
    "gpt-4-vision-preview",
    "gpt-4-0125-preview",
    "gpt-4-0613",
    "gpt-4-32k-0613",
    "gpt-3.5-turbo-0125",
    "gpt-3.5-turbo-instruct",
    "gpt-4-0314",
    "gpt-4-32k-0314",
    "gpt-3.5-turbo-0613",
    "gpt-3.5-turbo-16k-0613"
  ],
  "MISTRAL_MODELS": [
    "mistral-tiny",
    "mistral-small",
    "mistral-medium",
    "mistral-large-latest",
    "mistral-embed",
    "mistral-small-2402",
    "mistral-medium-2312"
  ],
  "OLLAMA_MODELS": [
    "llama2",
    "mistral",
    "codellama",
    "phi",
    "vicuna",
    "orca-mini",
    "neural-chat",
    "starling-lm",
    "stablelm-zephyr",
    "openhermes"
  ],
  "NVIDIA_MODELS": [
    "mixtral-8x7b-instruct-v0.1",
    "llama2-70b-instruct-v1",
    "llama2-13b-instruct-v1",
    "yi-34b-instruct-v1",
    "nemotron-3-8b-chat-v1",
    "stable-diffusion-xl-v1-base",
    "playground-v2"
  ],
  "COHERE_MODELS": [
    "command",
    "command-light",
    "command-nightly",
    "command-r",
    "command-light-r"
  ],
  "GROQ_MODELS": [
    "llama2-70b-4096",
    "mixtral-8x7b-32768",
    "gemma-7b-it"
  ],
  "VERTEXAI_MODELS": [
    "chat-bison",
    "chat-bison@001",
    "codechat-bison",
    "codechat-bison@001",
    "chat-bison-32k",
    "chat-bison-32k@002",
    "gemini-pro",
    "gemini-pro-vision"
  ],
  "ANTHROPIC_MODELS": [
    "claude-3-opus-20240229",
    "claude-3-sonnet-20240229",
    "claude-3-haiku-20240307",
    "claude-2.1",
    "claude-2.0",
    "claude-instant-1.2"
  ],
  "FIREWORKS_MODELS": [
    "llama-v2-7b-chat",
    "llama-v2-13b-chat",
    "llama-v2-70b-chat",
    "mixtral-8x7b-instruct",
    "mistral-7b-instruct-4k",
    "qwen-72b-chat"
  ]
}
